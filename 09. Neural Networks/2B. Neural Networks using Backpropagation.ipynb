{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['y', 'X', '__version__', '__header__', '__globals__']\n",
      "['Theta2', '__version__', '__header__', 'Theta1', '__globals__']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"machine_learning_andrewng/ex3data1.mat\")\n",
    "weights = loadmat(\"machine_learning_andrewng/ex3weights.mat\")\n",
    "print(data.keys())\n",
    "print(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "y = pd.get_dummies(y.ravel()).values\n",
    "theta1_loaded = weights[\"Theta1\"]\n",
    "theta2_loaded = weights[\"Theta2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return(1 / (1 + np.exp(-z)))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return(sigmoid(z)*(1-sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, theta1, theta2, elaborate=False):\n",
    "    a1 = np.c_[np.ones(X.shape[0]), X]\n",
    "    z2 = theta1.dot(a1.T) # 25x401 * 401x5000 = 25x5000\n",
    "    a2 = sigmoid(z2.T) # 5000x25\n",
    "    a2 = np.c_[np.ones(a1.shape[0]), a2] # 5000x26\n",
    "    z3 = theta2.dot(a2.T) # 10x26 * 26x5000 = 10x5000\n",
    "    a3 = sigmoid(z3.T) # 5000x10\n",
    "    if elaborate:\n",
    "        return ((X, a1, a2, a3), (z2, z3))\n",
    "    return a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_forward_pass(thetas, X, y, elaborate=True, *args):\n",
    "    print(\"thetas size:\", thetas.shape)\n",
    "    print(\"X size:\", X.shape)\n",
    "    print(\"y size:\", y_true.shape)\n",
    "    theta1 = thetas[:10025]\n",
    "    theta1 = theta1.reshape(25, 401)\n",
    "    theta2 = thetas[10025:]\n",
    "    theta2 = theta2.reshape(10, 26)\n",
    "    a1 = np.c_[np.ones(X.shape[0]), X]\n",
    "    z2 = theta1.dot(a1.T) # 25x401 * 401x5000 = 25x5000\n",
    "    a2 = sigmoid(z2.T) # 5000x25\n",
    "    a2 = np.c_[np.ones(a1.shape[0]), a2] # 5000x26\n",
    "    z3 = theta2.dot(a2.T) # 10x26 * 26x5000 = 10x5000\n",
    "    a3 = sigmoid(z3.T) # 5000x10\n",
    "    if elaborate:\n",
    "        return ((X, a1, a2, a3), (z2, z3))\n",
    "    return a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(X, y_true, theta1, theta2, lambda_=0):\n",
    "    m = X.shape[0]\n",
    "    y_pred = forward_pass(X, theta1, theta2)\n",
    "    positive_loss = np.sum(np.multiply(y_true, np.log(y_pred)).flatten())\n",
    "    negative_loss = np.sum(np.multiply((1 - y_true), np.log(1 - y_pred)).flatten())\n",
    "    regularization = (lambda_/(2*m)) * (np.sum(theta1.flatten() ** 2) + np.sum(theta2.flatten() ** 2))\n",
    "    J = - (1/m) * (positive_loss + negative_loss) + regularization\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_cross_entropy(thetas, X, y_true):\n",
    "    lambda_=0\n",
    "    m = X.shape[0]\n",
    "    theta1 = thetas[:10025]\n",
    "    theta1 = theta1.reshape(25, 401)\n",
    "    theta2 = thetas[10025:]\n",
    "    theta2 = theta2.reshape(10, 26)\n",
    "    y_pred = forward_pass(X, theta1, theta2)\n",
    "    positive_loss = np.sum(np.multiply(y_true, np.log(y_pred)).flatten())\n",
    "    negative_loss = np.sum(np.multiply((1 - y_true), np.log(1 - y_pred)).flatten())\n",
    "    regularization = (lambda_/(2*m)) * (np.sum(theta1.flatten() ** 2) + np.sum(theta2.flatten() ** 2))\n",
    "    J = - (1/m) * (positive_loss + negative_loss) + regularization\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.38448779624289398"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(X, y, theta1_loaded, theta2_loaded, lambda_=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "def backward_pass(X, y_true, theta1, theta2, *args):\n",
    "    ((X, a1, a2, y_pred), (z2, z3)) = forward_pass(X, theta1, theta2, elaborate=True)\n",
    "    delta3 = np.multiply((y_pred - y_true), sigmoid_prime(z3.T))\n",
    "    theta2_grad = a2.T.dot(delta3)\n",
    "    theta2_grad = theta2_grad.T # theta2_grad.shape is now same as theta2.shape\n",
    "    delta2 = np.multiply(delta3.dot(theta2[:, 1:]), sigmoid_prime(z2.T))\n",
    "    theta1_grad = a1.T.dot(delta2)\n",
    "    theta1_grad = theta1_grad.T\n",
    "    return theta1_grad, theta2_grad    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_backward_pass(thetas, X, y_true, *args):\n",
    "    theta1 = thetas[:10025]\n",
    "    theta1 = theta1.reshape(25, 401)\n",
    "    theta2 = thetas[10025:]\n",
    "    theta2 = theta2.reshape(10, 26)\n",
    "    ((X, a1, a2, y_pred), (z2, z3)) = forward_pass(X, theta1, theta2, elaborate=True)\n",
    "    delta3 = np.multiply((y_pred - y_true), sigmoid_prime(z3.T))\n",
    "    theta2_grad = a2.T.dot(delta3)\n",
    "    theta2_grad = theta2_grad.T # theta2_grad.shape is now same as theta2.shape\n",
    "    delta2 = np.multiply(delta3.dot(theta2[:, 1:]), sigmoid_prime(z2.T))\n",
    "    theta1_grad = a1.T.dot(delta2)\n",
    "    theta1_grad = theta1_grad.T\n",
    "    return np.r_[theta1_grad.flatten(), theta2_grad.flatten()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = np.random.rand(25, 401)\n",
    "theta2 = np.random.rand(10, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X, a1, a2, y_pred), (z2, z3)) = forward_pass(X, theta1, theta2, elaborate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 99 Cost: 114.125000263\r"
     ]
    }
   ],
   "source": [
    "def train(X, y, theta1, theta2):\n",
    "    n_epochs = 100\n",
    "    alpha = 0.001\n",
    "    for i in range(1, n_epochs):\n",
    "        y_pred = forward_pass(X, theta1, theta2)\n",
    "        cost = cross_entropy(X, y, theta1, theta2)\n",
    "        print \"Iteration: {0} Cost: {1}\\r\".format(i, cost),\n",
    "        theta1_grad, theta2_grad = backward_pass(X, y, theta1, theta2)\n",
    "        theta1 = theta1 - alpha * theta1_grad\n",
    "        theta2 = theta2 - alpha * theta2_grad\n",
    "train(X, y, theta1, theta2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113.44899464670516"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(X, y, theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "thetas = np.r_[theta1.flatten(), theta2.flatten()]\n",
    "res = minimize(sci_cross_entropy, thetas, jac=sci_backward_pass, options={'maxiter': 10000}, args=(X, y), method='cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 113.02232249649792\n",
       "     jac: array([  1.37156087e-07,   0.00000000e+00,   0.00000000e+00, ...,\n",
       "         2.24873345e-02,   2.24873169e-02,   2.24872804e-02])\n",
       " message: 'Desired error not necessarily achieved due to precision loss.'\n",
       "    nfev: 48\n",
       "     nit: 0\n",
       "    njev: 37\n",
       "  status: 2\n",
       " success: False\n",
       "       x: array([ 0.1300368 ,  0.64270156,  0.06006174, ...,  0.91566874,\n",
       "        0.47741502,  0.35878008])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
