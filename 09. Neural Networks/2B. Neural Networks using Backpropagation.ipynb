{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])\n",
      "dict_keys(['__header__', '__version__', '__globals__', 'Theta1', 'Theta2'])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from scipy.io import loadmat\n",
    "\n",
    "data = loadmat(\"machine_learning_andrewng/ex4data1.mat\")\n",
    "weights = loadmat(\"machine_learning_andrewng/ex3weights.mat\")\n",
    "print(data.keys())\n",
    "print(weights.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['X']\n",
    "y = data['y']\n",
    "y = pd.get_dummies(y.ravel()).values\n",
    "theta1_loaded = weights[\"Theta1\"]\n",
    "theta2_loaded = weights[\"Theta2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return(1 / (1 + np.exp(-z)))\n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    return(sigmoid(z)*(1-sigmoid(z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_pass(X, theta1, theta2, elaborate=False):\n",
    "    a1 = np.c_[np.ones(X.shape[0]), X]\n",
    "    z2 = theta1.dot(a1.T) # 25x401 * 401x5000 = 25x5000\n",
    "    a2 = sigmoid(z2.T) # 5000x25\n",
    "    a2 = np.c_[np.ones(a2.shape[0]), a2] # 5000x26\n",
    "    z3 = theta2.dot(a2.T) # 10x26 * 26x5000 = 10x5000\n",
    "    a3 = sigmoid(z3.T) # 5000x10\n",
    "    if elaborate:\n",
    "        return ((X, a1, a2, a3), (z2, z3))\n",
    "    return a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_forward_pass(thetas, X, y, elaborate=True, *args):\n",
    "    print(\"thetas size:\", thetas.shape)\n",
    "    print(\"X size:\", X.shape)\n",
    "    print(\"y size:\", y_true.shape)\n",
    "    theta1 = thetas[:10025]\n",
    "    theta1 = theta1.reshape(25, 401)\n",
    "    theta2 = thetas[10025:]\n",
    "    theta2 = theta2.reshape(10, 26)\n",
    "    a1 = np.c_[np.ones(X.shape[0]), X]\n",
    "    z2 = theta1.dot(a1.T) # 25x401 * 401x5000 = 25x5000\n",
    "    a2 = sigmoid(z2.T) # 5000x25\n",
    "    a2 = np.c_[np.ones(a1.shape[0]), a2] # 5000x26\n",
    "    z3 = theta2.dot(a2.T) # 10x26 * 26x5000 = 10x5000\n",
    "    a3 = sigmoid(z3.T) # 5000x10\n",
    "    if elaborate:\n",
    "        return ((X, a1, a2, a3), (z2, z3))\n",
    "    return a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(X, y_true, theta1, theta2, lambda_=0):\n",
    "    m = X.shape[0]\n",
    "    y_pred = forward_pass(X, theta1, theta2)\n",
    "    positive_loss = np.sum(np.multiply(y_true, np.log(y_pred)).flatten())\n",
    "    negative_loss = np.sum(np.multiply((1 - y_true), np.log(1 - y_pred)).flatten())\n",
    "    regularization = (lambda_/(2*m)) * (np.sum(theta1.flatten() ** 2) + np.sum(theta2.flatten() ** 2))\n",
    "#     regularization = 0\n",
    "    J = - (1/m) * (positive_loss + negative_loss) + regularization\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_cross_entropy(thetas, X, y_true):\n",
    "#     print(\"Thetas:\", thetas.shape)\n",
    "#     print(\"X:\", X.shape)\n",
    "#     print(\"y:\", y.shape)\n",
    "    lambda_ = 0\n",
    "    m = X.shape[0]\n",
    "    theta1 = thetas[:10025]\n",
    "    theta1 = theta1.reshape(25, 401)\n",
    "    theta2 = thetas[10025:]\n",
    "    theta2 = theta2.reshape(10, 26)\n",
    "    y_pred = forward_pass(X, theta1, theta2)\n",
    "    positive_loss = np.sum(np.multiply(y_true, np.log(y_pred)).flatten())\n",
    "    negative_loss = np.sum(np.multiply((1 - y_true), np.log(1 - y_pred)).flatten())\n",
    "    regularization = (lambda_/(2*m)) * (np.sum(theta1[:, 1:].flatten() ** 2) + np.sum(theta2[:, 1:].flatten() ** 2))\n",
    "    J = - (1/m) * (positive_loss + negative_loss) + regularization\n",
    "    print(J)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28762916516131887"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(X, y, theta1_loaded, theta2_loaded, lambda_=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original\n",
    "def backward_pass(X, y_true, theta1, theta2, *args):\n",
    "    ((X, a1, a2, y_pred), (z2, z3)) = forward_pass(X, theta1, theta2, elaborate=True)\n",
    "    delta3 = np.multiply((y_pred - y_true), sigmoid_prime(z3.T))\n",
    "    theta2_grad = a2.T.dot(delta3)\n",
    "    theta2_grad = theta2_grad.T # theta2_grad.shape is now same as theta2.shape\n",
    "    delta2 = np.multiply(delta3.dot(theta2[:, 1:]), sigmoid_prime(z2.T))\n",
    "    theta1_grad = a1.T.dot(delta2)\n",
    "    theta1_grad = theta1_grad.T\n",
    "    return theta1_grad, theta2_grad    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sci_backward_pass(thetas, X, y_true, *args):\n",
    "    theta1 = thetas[:10025]\n",
    "    theta1 = theta1.reshape(25, 401)\n",
    "    theta2 = thetas[10025:]\n",
    "    theta2 = theta2.reshape(10, 26)\n",
    "    ((X, a1, a2, y_pred), (z2, z3)) = forward_pass(X, theta1, theta2, elaborate=True)\n",
    "    delta3 = np.multiply((y_pred - y_true), sigmoid_prime(z3.T))\n",
    "    theta2_grad = a2.T.dot(delta3)\n",
    "    theta2_grad = theta2_grad.T # theta2_grad.shape is now same as theta2.shape\n",
    "    delta2 = np.multiply(delta3.dot(theta2[:, 1:]), sigmoid_prime(z2.T))\n",
    "    theta1_grad = a1.T.dot(delta2)\n",
    "    theta1_grad = theta1_grad.T\n",
    "    return np.r_[theta1_grad.flatten(), theta2_grad.flatten()]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = np.random.rand(25, 401)\n",
    "theta2 = np.random.rand(10, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "((X, a1, a2, y_pred), (z2, z3)) = forward_pass(X, theta1, theta2, elaborate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 99 Cost: 114.125000263\r"
     ]
    }
   ],
   "source": [
    "def train(X, y, theta1, theta2):\n",
    "    n_epochs = 100\n",
    "    alpha = 0.001\n",
    "    for i in range(1, n_epochs):\n",
    "        y_pred = forward_pass(X, theta1, theta2)\n",
    "        cost = cross_entropy(X, y, theta1, theta2)\n",
    "        print \"Iteration: {0} Cost: {1}\\r\".format(i, cost),\n",
    "        theta1_grad, theta2_grad = backward_pass(X, y, theta1, theta2)\n",
    "        theta1 = theta1 - alpha * theta1_grad\n",
    "        theta2 = theta2 - alpha * theta2_grad\n",
    "train(X, y, theta1, theta2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.9314718055994531"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(X, y, theta1, theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.33715033747\n",
      "7.33715028338\n",
      "7.33715030386\n",
      "7.3253564372\n",
      "7.26670313089\n",
      "5.96861507514\n",
      "6.86325408551\n",
      "4.06673376641\n",
      "4.06673363932\n",
      "3.99208440399\n",
      "3.6702837872\n",
      "5.99281095719\n",
      "4.8416659062\n",
      "3.76417997489\n",
      "3.3371023001\n",
      "3.37345572497\n",
      "3.32520980153\n",
      "3.32520979876\n",
      "3.32520978428\n",
      "3.32520971827\n",
      "3.31028035608\n",
      "3.2588820162\n",
      "9.56815879675\n",
      "5.93179370665\n",
      "3.78280641266\n",
      "3.34063961082\n",
      "3.26088837453\n",
      "3.25107052326\n",
      "3.25107051158\n",
      "3.25107051152\n",
      "3.238778801\n",
      "3.19971182086\n",
      "3.19971180539\n",
      "3.18542448139\n",
      "3.11741877846\n",
      "5.88339278296\n",
      "3.76946208677\n",
      "3.04668501771\n",
      "3.02585565774\n",
      "3.01696465318\n",
      "3.01696457948\n",
      "3.01696457616\n",
      "3.01695682174\n",
      "3.00777531775\n",
      "2.96377234283\n",
      "4.55313967164\n",
      "3.19454413708\n",
      "2.8201868917\n",
      "2.82018648856\n",
      "2.8201867583\n",
      "2.82018661145\n",
      "2.82017952609\n",
      "2.81156175566\n",
      "2.76880823337\n",
      "2.09934743485\n",
      "2.09934637102\n",
      "2.0993472968\n",
      "2.0993471675\n",
      "2.09934718773\n",
      "2.09440974675\n",
      "2.07002141702\n",
      "1.63196379662\n",
      "1.6905231215\n",
      "1.50569150703\n",
      "1.50569129733\n",
      "1.50569099816\n",
      "1.50569139854\n",
      "1.50569137284\n",
      "1.50569126605\n",
      "1.50568870174\n",
      "1.50222379717\n",
      "1.48509889012\n",
      "1.31515320759\n",
      "1.3279564852\n",
      "1.30572468829\n",
      "1.30572444889\n",
      "1.30572455471\n",
      "1.3057246359\n",
      "1.30572457307\n",
      "1.30572456087\n",
      "1.30572393837\n",
      "1.30233736172\n",
      "1.28554882689\n",
      "0.984199834358\n",
      "0.930280661653\n",
      "0.949750244631\n",
      "0.934396635036\n",
      "0.930994588463\n",
      "0.930308886973\n",
      "0.930213467173\n",
      "0.930213353014\n",
      "0.930213431615\n",
      "0.930213422143\n",
      "0.930213428103\n",
      "0.9302132062\n",
      "0.927993640411\n",
      "0.917049195366\n",
      "0.76169320233\n",
      "0.761693095779\n",
      "0.761693180353\n",
      "0.761693179528\n",
      "0.761693173955\n",
      "0.761693172632\n",
      "0.761693090241\n",
      "0.761692253873\n",
      "0.759783392433\n",
      "0.750350202847\n",
      "0.673929655536\n",
      "0.664970861939\n",
      "0.656985955871\n",
      "0.656985857408\n",
      "0.656985930112\n",
      "0.656985926771\n",
      "0.656985942673\n",
      "0.656985938198\n",
      "0.656985939969\n",
      "0.656985917731\n",
      "0.656985887909\n",
      "0.656985283886\n",
      "0.655321406282\n",
      "0.647076378027\n",
      "0.574729831002\n",
      "0.570755767235\n",
      "0.56189946078\n",
      "0.561899349089\n",
      "0.561899439426\n",
      "0.561899444417\n",
      "0.561899451114\n",
      "0.56189944596\n",
      "0.561899447609\n",
      "0.561899422604\n",
      "0.561899307684\n",
      "0.560491594411\n",
      "0.55357064111\n",
      "0.50251435834\n",
      "0.498050404712\n",
      "0.493625869212\n",
      "0.493625798774\n",
      "0.493625851659\n",
      "0.493625853761\n",
      "0.49362586275\n",
      "0.49362586284\n",
      "0.493625860096\n",
      "0.493625859883\n",
      "0.493625855775\n",
      "0.493625858394\n",
      "0.493625855384\n",
      "0.49362583505\n",
      "0.49362570861\n",
      "0.492337111296\n",
      "0.493625869212\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "thetas = np.r_[theta1.flatten(), theta2.flatten()]\n",
    "res = minimize(sci_cross_entropy, thetas, jac=sci_backward_pass, args=(X, y), options={'maxiter':150}, method=\"tnc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def genRandThetas():\n",
    "    epsilon_init = 0.12\n",
    "    theta1_shape = (25, 401)\n",
    "    theta2_shape = (10, 26)\n",
    "    rand_thetas = [ np.random.rand( *theta1_shape ) * 2 * epsilon_init - epsilon_init, \\\n",
    "                    np.random.rand( *theta2_shape ) * 2 * epsilon_init - epsilon_init]\n",
    "    return rand_thetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "thetas = genRandThetas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta1 = thetas[0]\n",
    "theta2 = thetas[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 401)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "     fun: 0.76169320232960236\n",
       "     jac: array([  2.50401351,   0.        ,   0.        , ...,  -1.38358507,\n",
       "        -4.88610398, -10.18670446])\n",
       " message: 'Max. number of function evaluations reached'\n",
       "    nfev: 100\n",
       "     nit: 11\n",
       "  status: 3\n",
       " success: False\n",
       "       x: array([-0.09833424, -0.10760554,  0.0189685 , ..., -2.97267521,\n",
       "       -1.3471328 ,  0.78219268])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, n_hidden, n_output, lambda_=0):\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_output = n_output\n",
    "        self.thetas = x\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        if y.shape[1] != self.n_output:\n",
    "            raise ValueError(\"Number of columns in y ({0}) are != to number \"\n",
    "                             \"of output neurons ({1})\".format(y.shape[1],\n",
    "                                                              self.n_output))\n",
    "\n",
    "    @staticmethod\n",
    "    def sigmoid(z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_prime(self, z):\n",
    "        return self.sigmoid(z) * (1 - self.sigmoid(z))\n",
    "\n",
    "    def cross_entropy(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        y_pred = self.forward_pass(X, theta1, theta2)\n",
    "        positive_loss = np.sum(np.multiply(y_true, np.log(y_pred)).flatten())\n",
    "        negative_loss = np.sum(\n",
    "            np.multiply((1 - y), np.log(1 - y_pred)).flatten())\n",
    "        regularization = (self.lambda_ / (2 * m)) * (np.sum(theta1.flatten() ** 2) + np.sum(theta2.flatten() ** 2))\n",
    "        # regularization = 0\n",
    "        J = - (1 / m) * (positive_loss + negative_loss) + regularization\n",
    "        return J\n",
    "\n",
    "    def forward_pass(X, theta1, theta2, elaborate=False):\n",
    "        a1 = np.c_[np.ones(X.shape[0]), X]\n",
    "        z2 = theta1.dot(a1.T)  # 25x401 * 401x5000 = 25x5000\n",
    "        a2 = sigmoid(z2.T)  # 5000x25\n",
    "        a2 = np.c_[np.ones(a2.shape[0]), a2]  # 5000x26\n",
    "        z3 = theta2.dot(a2.T)  # 10x26 * 26x5000 = 10x5000\n",
    "        a3 = sigmoid(z3.T)  # 5000x10\n",
    "        if elaborate:\n",
    "            return (X, a1, a2, a3), (z2, z3)\n",
    "        return a3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
